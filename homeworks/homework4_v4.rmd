---
title: "Homework 4"
output: 
  html_document:
    code_folding: show
    theme:
      bg: "#202123"
      fg: "#B8BCC2"
      primary: "#EA80FC"
      secondary: "#00DAC6"
      base_font:
        google: Prompt
      heading_font:
        google: Proza Libre
---

```{r setup, include=FALSE}
.libPaths(c(
  "/home/jacinto/projects/spatial-statistics/renv/library/linux-arch-rolling/R-4.5/x86_64-pc-linux-gnu",
  "/home/jacinto/.cache/R/renv/sandbox/linux-arch-rolling/R-4.5/x86_64-pc-linux-gnu/9a444a72"
))

knitr::opts_chunk$set(
  echo = FALSE,         # show code
  message = FALSE,     # hide messages (like library load)
  warning = FALSE,     # hide warnings
  results = "markup",  # show cat() and print() output
  fig.show = "hold"    # show all plots after code chunk finishes
)
```

```{R}

load("../class files/data/RainData.RData")
# Install missing packages automatically
#options(repos = c(CRAN = "https://cloud.r-project.org"))
#packages <- c("geoR", "sp", "gstat")
#installed <- packages %in% rownames(installed.packages())
#if (any(!installed)) install.packages(packages[!installed])
library(geoR)
library(sf)
library(viridis)
library(sp)
## ls()
## [1] "Bas"             "Basquota32"      "Cal"             "Calabriaquota32"
## [5] "dati"            "grid.int"
#head(dati)
assigned_years <- c(1976, 1979, 1982)
colnames(Calabriaquota32) <- colnames(Basquota32)
grid <- rbind(Basquota32[, c(2:4)], Calabriaquota32[, c(2:4)])
grid[, 1:2] <- grid[, 1:2] / 1000
dati[, 6:7] <- dati[, 6:7] / 1000
## a) Interpolate the dependent variable on the estimation grid using kriging in a maximum likelihood framework. (choose variogram and trend, use the available covariates)
dati_1976 <- as.geodata(dati[dati$anno == 1976, ], coords.col = 7:6, data.col = 10, covar.col = 8, covar.names = "quota")
dati_1979 <- as.geodata(dati[dati$anno == 1979, ], coords.col = 7:6, data.col = 10, covar.col = 8, covar.names = "quota")
dati_1982 <- as.geodata(dati[dati$anno == 1982, ], coords.col = 7:6, data.col = 10, covar.col = 8, covar.names = "quota")
grid_geodata <- as.geodata(grid, coords.col = 1:2, covar.col = 3)
years_list <- list("1976" = dati_1976, "1979" = dati_1979, "1982" = dati_1982)
# lambda_mapping <- c("1976" = 0, "1979" = 0, "1982" = 0.5)
# Replicating kriging with geoR
lambda_mapping <- c()
for (year in names(years_list)) {
  res <- boxcoxfit(years_list[[year]]$data)
  lambda_mapping[year] <- res$lambda
}
variog_mapping <- c()

```

## Exploratory Analysis

We begin by visualizing our data, and its distribution.

```{R}

for (year in names(years_list)) {

  dev.new() # Opens a new graphics device

  par(mfrow = c(2, 2))

  plot(years_list[[year]], name = paste("Data for", year))

}

```

From this initial observation, we can see a general pattern of rainfall across the regions, as well as somewhat irregular normality patterns. However, to identify the best initial parameters to conduct our estimation, we must first plot an empirical variogram of each year of interest. And before that, we must first inspect the normality of our data.

```{R}
for (year in names(years_list)) {
  cat("year=", year, "p value=", format(shapiro.test(years_list[[year]]$data)$p.value, scientific = FALSE), "\n")
}
```

We can see that our values are not normally distributed, after a thorough exploration we noticed that log transformations and square root transformations of our data improved the normality, since our estimation tools give us flexibility with the usage of lambda values we decided to include them in our process by automatically idntifying them usng the boxcoxfit function.

```{R}


vv1_raw <- variog(years_list[["1976"]], lambda = lambda_mapping["1976"], trend = ~quota)
vv2_raw <- variog(years_list[["1979"]], lambda = lambda_mapping["1979"], trend = ~quota)
vv3_raw <- variog(years_list[["1982"]], lambda = lambda_mapping["1982"], trend = ~quota)

plot(vv1_raw, main = "Variog 1976", type = "b")
plot(vv2_raw, main = "Variog 1979", type = "b")
plot(vv3_raw, main = "Variog 1982", type = "b")



```

From the plots above we can see that the variograms become unstable after approx. 100 to 150 km. However, we must also identify a good limit that ensures isotropy. To do this, we perform a directional empirical variogram:

```{R}

vv1_4 <- variog4(years_list[["1976"]], lambda = lambda_mapping["1976"], trend = ~quota)
vv2_4 <- variog4(years_list[["1979"]], lambda = lambda_mapping["1979"], trend = ~quota)
vv3_4 <- variog4(years_list[["1982"]], lambda = lambda_mapping["1982"], trend = ~quota)

plot(vv1_4, main = "Variog 1976 Anisotropy", type = "b")
plot(vv2_4, main = "Variog 1979 Anisotropy", type = "b")
plot(vv3_4, main = "Variog 1982 Anisotropy", type = "b")

```

These plots allow us to see the decay after 100 kms for all years except 1982, which seems to worsen much sooner. However, we assume that 100 km is a good enough cutting point for our estimations.

The following variograms will be the ones used for our fitting:

```{R}

vv1 <- variog(years_list[["1976"]], lambda = lambda_mapping["1976"], trend = ~quota, max.dist = 100)
vv2 <- variog(years_list[["1979"]], lambda = lambda_mapping["1979"], trend = ~quota, max.dist = 100)
vv3 <- variog(years_list[["1982"]], lambda = lambda_mapping["1982"], trend = ~quota, max.dist = 100)
#variog_mapping["1976"] <- vv1
#variog_mapping["1979"] <- vv2
#variog_mapping["1982"] <- vv3

plot(vv1, main = "Variog 1976 Truncated: 100km", type = "b")
plot(vv2, main = "Variog 1979 Truncated: 100km", type = "b")
plot(vv3, main = "Variog 1982 Truncated: 100km", type = "b")

```

## Estimation

From our variograms we can spot certain possible models that could fit our data; we attempt the Spherical, Exponential, Matérn (kappa=5), and Gaussian models.

<small><em>Comment: The Gaussian model was not invertible; unsure as to why. Discuss with professor.</em></small>

For each model, we cross-validate them and compare their root mean square error and coefficient of variation.

From these results, we can identify that the lowest error values correspond to the spherical model for the year 1976 and the exponential model for the remaining years.

```{R}

xvalid_matern <- c()
matern_error <- c()
matern_cv <- c()

for (year in names(years_list)) {
  vv <- variog(years_list[[year]], lambda = lambda_mapping[year], trend = ~quota, max.dist = 100)
  vv_fit_matern <- variofit(vv, cov.model = "matern", max.dist = 100, kappa = 3)
  geostat_matern <- likfit(years_list[[year]],
    lambda = lambda_mapping[year],
    cov.model = "matern",
    ini.cov.pars = vv_fit_matern$cov.pars
  )
  xvalid_matern[year] <- xvalid(geodata = years_list[[year]], model = geostat_matern, locations.xvalid = "all")
  matern_error[year] <- sqrt(mean((xvalid_matern[year]$error^2))) # RMSE for Matérn
  matern_cv[year] <-mean(xvalid_matern[year]$std.error^2) 
}


xvalid_exp <- c()
exp_error <- c()
exp_cv <- c()
kk.a <- list()
krig0 <- list()

for (year in names(years_list)) {
  vv <- variog(years_list[[year]], lambda = lambda_mapping[year], trend = ~quota, max.dist = 100)
  vv_fit_exp <- variofit(vv, cov.model = "exponential", max.dist = 100)
  geostat_exp <- likfit(years_list[[year]],
    lambda = lambda_mapping[year],
    cov.model = "exponential",
    ini.cov.pars = vv_fit_exp$cov.pars
  )
  xvalid_exp[year] <- xvalid(geodata = years_list[[year]], model = geostat_exp, locations.xvalid = "all")
  exp_error[year] <- sqrt(mean((xvalid_exp[year]$error^2))) # rmse for matérn
  exp_cv[year] <-mean(xvalid_exp[year]$std.error^2)  
  kk.a[[year]] <- krige.control(obj.model = geostat_exp, lambda = lambda_mapping[year])
  krig0[[year]] <- krige.conv(years_list[[year]], locations = as.matrix(grid), krige = kk.a[[year]])
  if (year %in% c("1979", "1982")) {
    plot(vv, main = paste("Empirical vs Fitted Variogram -", year)) # base variogram
    lines(vv_fit_exp, col = "red", lwd = 2) # variofit (black)
  }
}

xvalid_sph <- c()
sph_error <- c()
sph_cv <- c()
kk.c <- list()
krig1 <- list()
for (year in names(years_list)) {
  vv <- variog(years_list[[year]], lambda = lambda_mapping[year], trend = ~quota, max.dist = 100)
  vv_fit_sph <- variofit(vv, cov.model = "spherical", max.dist = 100)
  geostat_sph <- likfit(years_list[[year]],
    lambda = lambda_mapping[year],
    cov.model = "spherical",
    ini.cov.pars = vv_fit_sph$cov.pars
  )
  xvalid_sph[year] <- xvalid(geodata = years_list[[year]], model = geostat_sph, locations.xvalid = "all")
  sph_error[year] <- sqrt(mean((xvalid_sph[year]$error^2))) # RMSE for Matérn
  sph_cv[year] <-mean(xvalid_sph[year]$std.error^2) 

  kk.c[[year]] <- krige.control(obj.model = geostat_sph, lambda = lambda_mapping[year])
  krig1[[year]] <- krige.conv(years_list[[year]], locations = as.matrix(grid), krige = kk.c[[year]])
  if (!(year %in% c("1979", "1982"))) {
    plot(vv, main = paste("Empirical vs Fitted Variogram -", year)) # base variogram
    lines(vv_fit_sph, col = "red", lwd = 2) # variofit (black)
  }
}
results <- data.frame(
  year = names(exp_error),
  sph_error = unlist(sph_error),
  sph_cv = unlist(sph_cv),
  exp_error = unlist(exp_error),
  exp_cv = unlist(exp_cv),
  matern_error = unlist(matern_error),
  matern_cv = unlist(matern_cv)
)
rownames(results) <- results$year
results$year <- NULL
results
print("kappa=5")

for (year in rownames(results)) {
  # extract the row of errors for this year
  errors <- results[year, grep("_error$", names(results))]

  # find which model has the lowest error
  best_model <- names(errors)[which.min(errors)]

  # print formatted result
  cat(year, "lowest value:", best_model, "\n")
}
```

Given this information, we proceed to use their parameters to estimate our beta values for each year, as well as the kriging of our predictions and the estimation of their confidence interval.

```{R}

# confidence interval
alpha <- qnorm(0.975)
kkl1976 <- krig1[["1976"]]$predict - alpha * sqrt(krig1[["1976"]]$krige.var)
kku1976 <- krig1[["1976"]]$predict + alpha * sqrt(krig1[["1976"]]$krige.var)


kkl1979 <- krig0[["1979"]]$predict - alpha * sqrt(krig1[["1979"]]$krige.var)
kku1979 <- krig0[["1979"]]$predict + alpha * sqrt(krig1[["1979"]]$krige.var)


kkl1982 <- krig0[["1982"]]$predict - alpha * sqrt(krig1[["1982"]]$krige.var)
kku1982 <- krig0[["1982"]]$predict + alpha * sqrt(krig1[["1982"]]$krige.var)

results_1976 <- data.frame(
  XUTM = grid[, "XUTM"],
  YUTM = grid[, "YUTM"],
  pred = krig1[["1976"]]$predict,
  var = krig1[["1976"]]$krige.var,
  lower95 = kkl1976,
  upper95 = kku1976
)
coordinates(results_1976) <- ~ XUTM + YUTM


results_1979 <- data.frame(
  XUTM = grid[, "XUTM"],
  YUTM = grid[, "YUTM"],
  pred = krig0[["1979"]]$predict,
  var = krig0[["1979"]]$krige.var,
  lower95 = kkl1979,
  upper95 = kku1979
)
coordinates(results_1979) <- ~ XUTM + YUTM



results_1982 <- data.frame(
  XUTM = grid[, "XUTM"],
  YUTM = grid[, "YUTM"],
  pred = krig0[["1982"]]$predict,
  var = krig0[["1982"]]$krige.var,
  lower95 = kkl1982,
  upper95 = kku1982
)
coordinates(results_1982) <- ~ XUTM + YUTM

library(sp)
# 1976
p1<-spplot(results_1976,pretty=TRUE,scales=list(draw=TRUE), zcol = "pred", main = "Rain data - 1976")
p2<-spplot(results_1976,pretty=TRUE,scales=list(draw=TRUE), zcol = "lower95", main = "Rain data - 1976 (LB)")
p3<-spplot(results_1976,pretty=TRUE,scales=list(draw=TRUE), zcol = "upper95", main = "Rain data - 1976 (UP)")
  gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
# 1979
p1<-spplot(results_1979,pretty=TRUE,scales=list(draw=TRUE), zcol = "pred", main = "Rain data - 1979", col.regions = topo.colors(100))
p2<-spplot(results_1979,pretty=TRUE,scales=list(draw=TRUE), zcol = "lower95", main = "Rain data - 1979 (LB)", col.regions = topo.colors(100))
p3<-spplot(results_1979,pretty=TRUE,scales=list(draw=TRUE), zcol = "upper95", main = "Rain data - 1979 (UP)", col.regions = topo.colors(100))
  gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
# 1982
p1<-spplot(results_1982,pretty=TRUE,scales=list(draw=TRUE), zcol = "pred", main = "Rain data - 1982", col.regions = topo.colors(100))
p2<-spplot(results_1982,pretty=TRUE,scales=list(draw=TRUE), zcol = "lower95", main = "Rain data - 1982 (LB)", col.regions = viridis(100))
p3<-spplot(results_1982,pretty=TRUE,scales=list(draw=TRUE), zcol = "upper95", main = "Rain data - 1982 (UP)", col.regions = viridis(100))
  gridExtra::grid.arrange(p1, p2, p3, ncol = 3)

```

This concludes our estimation of each year of rainfall data using the ML method.

## Comments

Overall we can see a general pattern of rainfall present around the western coast of Basc and Cal. This pattern is consistent across all years and could point to a proper general estimation of where rain occurs in these regions. Additionally, these patterns remain consistent even after estimating the upper and lower bounds, as well as generally following the original pattern of the data (as intended).

There are still concerning aspects of our estimation. Our errors seem to be relatively high, and while our rainfall estimates remain consistent with a somewhat stable spatial distribution, our variance gives us very wide confidence intervals, with hardly enough additional information added by our model.

Below we can see some quality measurements of our final estimation, particularly the ratio between the variance of our prediction and the variance of our data, as well as the median value of the relative width of each point.

```{R}
#1976
mean(results_1976$var, na.rm=TRUE) / var(results_1976$pred, na.rm=TRUE)

results_1976$ci_width_rel <- (results_1976$upper95 - results_1976$lower95) / results_1976$pred
summary(results_1976$ci_width_rel)
#
#library(ggplot2)
#ggplot(results_1976@data, aes(x = pred, y = sqrt(var))) +
#  geom_point(alpha = 0.6) +
#  labs(x = "Predicted value", y = "Prediction Std. Dev.",
#       title = "Uncertainty vs. Predicted value (1976)") +
#  theme_minimal()

#1979
mean(results_1979$var, na.rm=TRUE) / var(results_1979$pred, na.rm=TRUE)

results_1979$ci_width_rel <- (results_1979$upper95 - results_1979$lower95) / results_1979$pred
summary(results_1979$ci_width_rel)
##
##library(ggplot2)
##ggplot(results_1979@data, aes(x = pred, y = sqrt(var))) +
##  geom_point(alpha = 0.6) +
##  labs(x = "Predicted value", y = "Prediction Std. Dev.",
##       title = "Uncertainty vs. Predicted value (1979)") +
##  theme_minimal()

#1982
mean(results_1982$var, na.rm=TRUE) / var(results_1982$pred, na.rm=TRUE)

results_1982$ci_width_rel <- (results_1982$upper95 - results_1982$lower95) / results_1982$pred
summary(results_1982$ci_width_rel)
#
#library(ggplot2)
#ggplot(results_1982@data, aes(x = pred, y = sqrt(var))) +
#  geom_point(alpha = 0.6) +
#  labs(x = "Predicted value", y = "Prediction Std. Dev.",
#       title = "Uncertainty vs. Predicted value (1982)") +
#  theme_minimal()

```

Besides selecting our best model based on meassurement error, we can see by our coefficient of variation that our models are generally well defined, whith values close to 1, for the year 1976 the relationship betwene the model's root mean square error and variation coefficient are seemingly inverse, which could suggest exploratory analysis on matern or spherical models for that year for even better results, however, the presently used model already has the best overall variation reduction and signficance levels.  

Our worst estimate seems to be 1982, which also has a particularly explosive directional empirical variogram, and our second worst estimate is 1979, which has a very unusual growth pattern in the empirical variogram for the first few kilometers.

Overall our estimates are "good enough" in the sense that they provide minimally useful information, but they could be improved (perhaps creative use of covariates across years, algorithmic exploration of kappa values for the matern model, or dynamic cross validation with multiple parameters, as well as Bayesian estimation).
